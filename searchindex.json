{"categories":[{"title":"Algorithms","uri":"https://niuez.github.io/categories/algorithms/"}],"posts":[{"content":"BFS Euler TourについてはBFS Euler Tour - niuez.github.ioを参照してください.\n処理したいクエリ (例) 有向木が与えられ, 各頂点には重みがある.\n 頂点$v$から, 辺をちょうど$d$個たどって到達できる頂点の重みの総和を出力  総和じゃなくても更新とかもしたいよね.\nアルゴリズム BFS Euler Tourをすると, 同じ深さの頂点が並ぶということは上の記事をみるとわかります. これにDFS Euler Tourしたときの情報を合わせることで任意深さについで, BFS Euler Tourしたときの区間を前計算$O(N)$, クエリ$O(\\log N)$で求めることができます.\n[](./images/bfs_dfs.png)\nBFS Euler Tourしたときの順番と, DFS Euler Tourしたときの$in/out$を各ノードに添えました. ただし, ノードの子供を探索する順序はDFS, BFS共に同じにします, すると,\n 深さ$0$のノードのbfsの番号と$in$  bfs: 0 in : 0   深さ$1$のノードのbfsの番号と$in$  bfs: 1 2 in : 1 8   深さ$2$のノードのbfsの番号と$in$  bfs: 3 4 5 6 in : 2 5 9 12   深さ$3$のノードのbfsの番号と$in$  bfs: 7 8 9 10 11 12 13 14 in : 3 4 6 7 10 11 13 14  となり, 単調増加します.\nまた, DFS Euler Tourでは, ある頂点$v$の$[in, out)$は, $v$を根とする部分木に含まれる頂点の$in$の集合です. これを活かして, 頂点$1$から深さ$2$の頂点のBFS Euler Tourの区間を求めてみます.\n木全体での頂点$1$の深さは$1$なので, 求めたい区間の頂点は深さ$3$です. また, 頂点$1$の$[in, out)$は$[1, 8)$です. なので求めたい頂点の$in$の値は, 深さ$3$での$in$の列の中で$[1, 8)$に含まれている$in = 3, 4, 6, 7$です. これは, BFS Euler Tourの区間では$[7, 10)$に相当します.\nこの操作は二分探索で行うことができるので, クエリあたり$O(\\log N)$です.\n実装  para[i] := BFS Euler Tourでi番目の頂点 inv_para[v] := BFS Euler Tourにおける頂点vのインデックス  struct bfs_euler_tour { int N; std::vector\u0026lt;std::vector\u0026lt;int\u0026gt;\u0026gt; G; std::vector\u0026lt;int\u0026gt; in; std::vector\u0026lt;int\u0026gt; out; std::vector\u0026lt;int\u0026gt; para; std::vector\u0026lt;int\u0026gt; inv_para; std::vector\u0026lt;int\u0026gt; dep; std::vector\u0026lt;int\u0026gt; par; std::vector\u0026lt;int\u0026gt; start; int cnt; int D; bfs_euler_tour(int N): N(N), G(N), in(N), out(N), para(N, -1), inv_para(N, -1), dep(N), par(N) {} void add_edge(int a, int b) { G[a].push_back(b); G[b].push_back(a); } void dfs(int v, int f, int depth) { D = std::max(D, depth); par[v] = f; dep[v] = depth; in[v] = cnt++; for(auto t: G[v]) { if(t == f) continue; dfs(t, v, depth + 1); } out[v] = cnt; } void build(int r) { cnt = 0; D = 0; dfs(r, -1, 0); D++; cnt = 0; std::vector\u0026lt;int\u0026gt; que(N); int ql = 0; int qr = 0; que[qr++] = r; start.resize(D + 1); for(int d = 0; ql \u0026lt; qr; d++) { int r = qr; start[d] = cnt; while(ql \u0026lt; r) { int v = que[ql++]; inv_para[v] = cnt; para[cnt++] = v; for(auto t: G[v]) { if(in[v] \u0026lt; in[t]) { que[qr++] = t; } } } } start[D] = cnt; } int para_lower_bound(int l, int r, int i) { while(r - l \u0026gt; 1) { int m = (l + r) \u0026gt;\u0026gt; 1; if(i \u0026lt;= in[para[m]]) { r = m; } else { l = m; } } return r; } std::pair\u0026lt;int, int\u0026gt; range(int v, int d) { if(dep[v] + d \u0026lt; D) { int l = start[dep[v] + d]; int r = start[dep[v] + d + 1]; return { para_lower_bound(l - 1, r, in[v]), para_lower_bound(l - 1, r, out[v]) }; } else { return { 0, 0 }; } } };  使用例 No.899 γathereeを解いてみました. #448690 (C++14) No.899 γatheree - yukicoder\nverify問題 びーと, ありがとう\n","id":0,"section":"posts","summary":"BFS Euler TourについてはBFS Euler Tour - niuez.github.ioを参照してください. 処理したいクエリ (例) 有向木が与えられ, 各頂点には重みが","tags":null,"title":"DFS+BFS EulerTourで部分木の任意深さのクエリを処理する","uri":"https://niuez.github.io/2020/03/dfs_bfs_et/","year":"2020"},{"content":"小山高専で, mitsuさん原案のコンテストOyamaCが行われました. testerを担当したので, 解説を書いておきます.\nfizzbuzz fizzbuzzは書けますか？N % 15から書くとスムーズです.\n#include \u0026lt;bits/stdc++.h\u0026gt; using namespace std; using i64 = long long; int main() { i64 N; cin \u0026gt;\u0026gt; N; if(N % 15 == 0) cout \u0026lt;\u0026lt; \u0026quot;fizzbuzz\u0026quot; \u0026lt;\u0026lt; endl; else if(N % 3 == 0) cout \u0026lt;\u0026lt; \u0026quot;fizz\u0026quot; \u0026lt;\u0026lt; endl; else if(N % 5 == 0) cout \u0026lt;\u0026lt; \u0026quot;buzz\u0026quot; \u0026lt;\u0026lt; endl; else cout \u0026lt;\u0026lt; N \u0026lt;\u0026lt; endl; }  tiktak 秒の単位換算です. 3600, 60で割ったあまりを計算していけばいいです.\n#include \u0026lt;bits/stdc++.h\u0026gt; using namespace std; using i64 = long long; int main() { i64 N; cin \u0026gt;\u0026gt; N; cout \u0026lt;\u0026lt; N / 3600 \u0026lt;\u0026lt; endl; N %= 3600; cout \u0026lt;\u0026lt; N / 60 \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; N % 60 \u0026lt;\u0026lt; endl; }  sumsumsum みつみつみつみたいですね(は？) これは, $x, y$を$D$をオーバーしない範囲で考えてあげれば, $z$が決まります. 実は, 原案は$1 \\le A, B, C, D \\le 10^6$でした. あなたは解けますか？\n#include \u0026lt;bits/stdc++.h\u0026gt; using namespace std; using i64 = long long; #define rep(i,s,e) for(i64 (i) = (s);(i) \u0026lt; (e);(i)++) #define all(x) x.begin(),x.end() int main() { i64 N = 3; vector\u0026lt;i64\u0026gt; A(N); rep(i,0,N) { cin \u0026gt;\u0026gt; A[i]; } i64 D; cin \u0026gt;\u0026gt; D; vector\u0026lt;vector\u0026lt;i64\u0026gt;\u0026gt; dp(N + 1, vector\u0026lt;i64\u0026gt;(D + 1, 0)); dp[0][0] = 1; rep(i,0,N) { rep(j,0,D + 1) { if(j \u0026gt;= A[i]) { dp[i + 1][j] = dp[i][j] + dp[i + 1][j - A[i]]; } else { dp[i + 1][j] = dp[i][j]; } } } cout \u0026lt;\u0026lt; dp[N][D] \u0026lt;\u0026lt; endl; }  uniform liner sushi これは蟻本にも書かれている, 区間スゲジューリング問題ですね. 後ろをなるべく小さくするように取る貪欲で解くことができます.\n#include \u0026lt;bits/stdc++.h\u0026gt; using namespace std; using i64 = long long; #define rep(i,s,e) for(i64 (i) = (s);(i) \u0026lt; (e);(i)++) #define all(x) x.begin(),x.end() int main() { i64 N; cin \u0026gt;\u0026gt; N; std::vector\u0026lt;pair\u0026lt;i64, i64\u0026gt;\u0026gt; vec; rep(i,0,N) { i64 s, t; cin \u0026gt;\u0026gt; s \u0026gt;\u0026gt; t; vec.push_back({ s + t, s }); } sort(all(vec)); vector\u0026lt;i64\u0026gt; ne(1, 0); i64 ans = 0; rep(i,0,N) { if(ne[0] \u0026lt;= vec[i].second) { ne[0] = vec[i].first; ans++; } } cout \u0026lt;\u0026lt; ans \u0026lt;\u0026lt; endl; }  rot and rot これが最後の砦だと思ってたんですけど, 皆さんどうでしたか？\n僕は行列を用いて移動を表現しました.\n $$ \\left( \\begin{array}{c} S \u0026 1 \\end{array} \\right) $$  に,\n $$ \\left( \\begin{array}{c} A + 1 \u0026 1 \\\\ B \u0026 0 \\end{array} \\right) $$  を掛けると, 1ステップです. なので, $N$ステップは,\n $$ \\left( \\begin{array}{c} S \u0026 1 \\end{array} \\right) \\left( \\begin{array}{c} A + 1 \u0026 0 \\\\ B \u0026 1 \\end{array} \\right) ^ N = \\left( \\begin{array}{c} S \u0026 1 \\end{array} \\right) \\left( \\begin{array}{c} (A + 1) ^ N \u0026 0 \\\\ ((A + 1)^N - 1) / ((A + 1) - 1) * B \u0026 1 \\end{array} \\right) ^ N $$  です. $A = 0$に注意が必要です. 行列累乗でも間に合うと思います.\n#include \u0026lt;bits/stdc++.h\u0026gt; using namespace std; using i64 = long long; #define rep(i,s,e) for(i64 (i) = (s);(i) \u0026lt; (e);(i)++) #define all(x) x.begin(),x.end() const i64 MOD = 1e9 + 7; #include \u0026lt;bits/stdc++.h\u0026gt; using namespace std; using i64 = long long; template\u0026lt;i64 M\u0026gt; constexpr i64 euinv(i64 val) { i64 a = M, b = val; i64 x = 0, u = 1; while (b) { i64 t = a / b; swap(a -= t * b, b); swap(x -= t * u, u); } return x \u0026lt; 0 ? x + M : x; } template\u0026lt;i64 M\u0026gt; struct modint { i64 a; constexpr modint(const i64 x = 0) noexcept: a((x % M + M) % M) {} constexpr i64 value() const noexcept { return a; } constexpr modint inv() const noexcept { return modint(euinv\u0026lt;M\u0026gt;(a)); } constexpr modint pow(i64 r) const noexcept { modint ans(1); modint aa = *this; while(r) { if(r \u0026amp; 1) { ans *= aa; } aa *= aa; r \u0026gt;\u0026gt;= 1; } return ans; } constexpr modint\u0026amp; operator+=(const modint r) noexcept { a += r.a; if(a \u0026gt;= M) a -= M; return *this; } constexpr modint\u0026amp; operator=(const i64 r) { a = (r % M + M) % M; return *this; } constexpr modint\u0026amp; operator-=(const modint r) noexcept { a -= r.a; if(a \u0026lt; 0) a += M; return *this; } constexpr modint\u0026amp; operator*=(const modint r) noexcept { a = a * r.a % M; return *this; } constexpr modint\u0026amp; operator/=(modint r) noexcept { i64 ex = M - 2; while(ex) { if(ex \u0026amp; 1) { *this *= r; } r *= r; ex \u0026gt;\u0026gt;= 1; } return *this; } constexpr modint operator+(const modint r) const { return modint(*this) += r; } constexpr modint operator-(const modint r) const { return modint(*this) -= r; } constexpr modint operator*(const modint r) const { return modint(*this) *= r; } constexpr modint operator/(const modint r) const { return modint(*this) /= r; } constexpr bool operator!=(const modint r) const { return this-\u0026gt;value() != r.value(); } }; template\u0026lt;const i64 M\u0026gt; std::ostream\u0026amp; operator\u0026lt;\u0026lt;(std::ostream\u0026amp; os, const modint\u0026lt;M\u0026gt;\u0026amp; m) { os \u0026lt;\u0026lt; m.value(); return os; } using fp = modint\u0026lt;MOD\u0026gt;; int main() { i64 S, A, B, N; cin \u0026gt;\u0026gt; S \u0026gt;\u0026gt; A \u0026gt;\u0026gt; B \u0026gt;\u0026gt; N; A++; if(A == 1) { cout \u0026lt;\u0026lt; fp(S) + fp(B) * fp(N) \u0026lt;\u0026lt; endl; }else { /* * p = 10^9 + 7, F_pでの演算を考える * * [S 1] * [ A + 1 0 ]^N * [ B 1 ] * * = [S 1] * [ (A + 1)^N 0 ] * [ ((A + 1)^N - 1) / ((A + 1) - 1) * B 1 ] */ cout \u0026lt;\u0026lt; fp(S) * fp(A).pow(N) + (fp(A).pow(N) - fp(1)) / (fp(A) - fp(1)) * fp(B) \u0026lt;\u0026lt; endl; } }  uniform liner sushi 2 2なのでふたつです. 基本区間スケジュールでやりますが, なるべく寿司が食べ終わるのが遅い方を優先的に食べさせるようにするといいです.\n#include \u0026lt;bits/stdc++.h\u0026gt; using namespace std; using i64 = long long; #define rep(i,s,e) for(i64 (i) = (s);(i) \u0026lt; (e);(i)++) #define all(x) x.begin(),x.end() int main() { i64 N; cin \u0026gt;\u0026gt; N; std::vector\u0026lt;pair\u0026lt;i64, i64\u0026gt;\u0026gt; vec; rep(i,0,N) { i64 s, t; cin \u0026gt;\u0026gt; s \u0026gt;\u0026gt; t; vec.push_back({ s + t, s }); } sort(all(vec)); vector\u0026lt;i64\u0026gt; ne(2, 0); i64 ans = 0; rep(i,0,N) { if(ne[1] \u0026lt;= vec[i].second) { ne[1] = vec[i].first; ans++; } else if(ne[0] \u0026lt;= vec[i].second) { ne[0] = vec[i].first; std::swap(ne[0], ne[1]); ans++; } } cout \u0026lt;\u0026lt; ans \u0026lt;\u0026lt; endl; }  storage ちょうど満杯, なので容量の情報は正確に持っておく必要があります. これを添え字にもつDPを考えるとよいです. また, $K$個以内については, 最小で何個を考えてやって, 最後にそれが$K$個以下かを判定すればよいです.\n#include \u0026lt;bits/stdc++.h\u0026gt; using namespace std; using i64 = long long; #define rep(i,s,e) for(i64 (i) = (s);(i) \u0026lt; (e);(i)++) #define all(x) x.begin(),x.end() template\u0026lt;class T\u0026gt; static inline std::vector\u0026lt;T\u0026gt; ndvec(size_t\u0026amp;\u0026amp; n, T val) noexcept { return std::vector\u0026lt;T\u0026gt;(n, std::forward\u0026lt;T\u0026gt;(val)); } template\u0026lt;class... Tail\u0026gt; static inline auto ndvec(size_t\u0026amp;\u0026amp; n, Tail\u0026amp;\u0026amp;... tail) noexcept { return std::vector\u0026lt;decltype(ndvec(std::forward\u0026lt;Tail\u0026gt;(tail)...))\u0026gt;(n, ndvec(std::forward\u0026lt;Tail\u0026gt;(tail)...)); } int main() { i64 A, N; cin \u0026gt;\u0026gt; A \u0026gt;\u0026gt; N; i64 K; cin \u0026gt;\u0026gt; K; vector\u0026lt;i64\u0026gt; W(N); rep(i,0,N) { cin \u0026gt;\u0026gt; W[i]; } vector\u0026lt;vector\u0026lt;i64\u0026gt;\u0026gt; dp(N + 1, vector\u0026lt;i64\u0026gt;(A + 1, 1e18)); dp[0][0] = 0; rep(i,0,N) { rep(j, 0, A + 1) { if(j \u0026gt;= W[i]) { dp[i + 1][j] = std::min(dp[i][j], dp[i][j - W[i]] + 1); } else { dp[i + 1][j] = dp[i][j]; } } } if(dp[N][A] \u0026lt;= K) { cout \u0026lt;\u0026lt; \u0026quot;YES\u0026quot; \u0026lt;\u0026lt; endl; } else { cout \u0026lt;\u0026lt; \u0026quot;NO\u0026quot; \u0026lt;\u0026lt; endl; } }  ","id":1,"section":"posts","summary":"小山高専で, mitsuさん原案のコンテストOyamaCが行われました. testerを担当したので, 解説を書いておきます. fizzbuzz fizzbuzzは","tags":null,"title":"OyamaC'20 解説","uri":"https://niuez.github.io/2020/03/oyamac20/","year":"2020"},{"content":"ABC155-F Perils in Parallel - kotatsugameの日記を読んだときのメモです.\nAtCoder F - Perils in Parallelを$\\mathbb{F}_2$上の行列として考えて解きます. 以下この問題のネタバレを含みます\n問題を簡単にする  座標$i \\ (0 \\le i \\le N)$のスイッチの状態が$B_i$ $i \\ (0 \\le i \\le M)$のコードは$[L_i, R_i) \\ (0 \\le L_i, R_i \\le N)$の範囲のスイッチのオンオフを切り替える.  とします.\n$L, R$を行列で表示 気持ちとしては,\n(コードを表した行列) * (コードを切ったか切っていないか) = (爆弾のスイッチを切り替えるか切り替えないか)  とすると嬉しい. なので,\n$(N, M)$型行列$A$ * $(M, 1)$型行列$\\vec{x}$ $=$ $(N, 1)$型行列$B$ という感じに.\nサンプル1で試してみます.\n3 4 5 1 10 1 8 0 1 10 4 5 6 7 8 9   $$ B = \\left( \\begin{array}{c} 1 \\\\ 0 \\\\ 1 \\end{array} \\right) $$   $$ A = \\left( \\begin{array}{ccc} 1 \u0026 1 \u0026 0 \u0026 0 \\\\ 1 \u0026 0 \u0026 0 \u0026 0 \\\\ 1 \u0026 0 \u0026 0 \u0026 1 \\end{array} \\right) $$  $A$は, 「どこの爆弾のスイッチを切り替えるか」を縦に並べて, それを横にくっつけた感じです.\n答えとなる$\\vec{x}$は,\n $$ \\vec{x} = \\left( \\begin{array}{c} 1 \\\\ 0 \\\\ 0 \\\\ 1 \\end{array} \\right) $$  となります.\n求め方 $A \\vec{x} = B$を解くわけなんですが, このままだと解きにくいので行列の基本変形をすることで, $A$を下三角行列に変換します. 行列の基本変形\n普通, 連立方程式を解く時は行の基本変形を行います. しかし, 掃き出し法は計算に時間がかかります. ここでは, 列の基本変形をすることで計算量が落ちることを使います. この証明は後にします.\n$A$に基本行列$P_1 P_2 \\cdots P_k$を右から掛けて(列の基本変形なので)$A'$と下三角行列に変形したとします. $A\u0026rsquo; \\vec{x\u0026rsquo;} = B$を解くのは簡単です.\n$\\vec{x\u0026rsquo;}$から$\\vec{x}$を求めることを考えます.\n$$ \\begin{eqnarray} A\u0026rsquo; \\vec{x\u0026rsquo;} \u0026amp;=\u0026amp; B \\\\\nA P_1 P_2 \\cdots P_k \\vec{x\u0026rsquo;} \u0026amp;=\u0026amp; A \\vec{x} \\\\\nP_1 P_2 \\cdots P_k \\vec{x\u0026rsquo;} \u0026amp;=\u0026amp; \\vec{x} \\\\\n\\end{eqnarray} $$\nとなるので, $\\vec{x\u0026rsquo;}$を$P_k$から行の基本変形していけば$\\vec{x}$が求まります.\n列の基本変形による計算量削減 縦方向には, $1$が連続していることを使えば, 計算量が削減できます.\n同じ始点$L$を持つ区間, $[L, R_1), [L, R_2), \\cdots, [L, R_n)$を$[L, R_1), [R_1, R_2), \\cdots, [R_{n-1}, R_n)$と掃き出します. すると, 以下のように計算量が計算できます.\n掃き出したときに区間が半分未満(ちょうど半分になっていく)になるとすると, $O(\\log N)$回しか処理されません. また, スイッチは$M$個なので$O(M \\log N)$です.\n区間が半分以上になるのは各$L \\ (0 \\le L \u0026lt; N)$について$O(\\log N)$個しか無いので$O(N \\log N)$です.\n合わせて$O((N+M) \\log N)$です.\n吐き出す前にソートが必要なので$O((N + M) \\log (N) \\log ((N + M) \\log N))$です.\nコード 提出 #10248008 - AtCoder Beginner Contest 155\n#include \u0026lt;bits/stdc++.h\u0026gt; using namespace std; using i64 = long long; #define rep(i,s,e) for(i64 (i) = (s);(i) \u0026lt; (e);(i)++) #define all(x) x.begin(),x.end() int main() { i64 N, M; cin \u0026gt;\u0026gt; N \u0026gt;\u0026gt; M; vector\u0026lt;pair\u0026lt;i64, i64\u0026gt;\u0026gt; vec; rep(i,0,N) { i64 a, b; cin \u0026gt;\u0026gt; a \u0026gt;\u0026gt; b; vec.push_back({ a, b }); } vector\u0026lt;i64\u0026gt; A(N), B(N); sort(all(vec)); rep(i,0,N) { A[i] = vec[i].first; B[i] = vec[i].second; } vector\u0026lt;i64\u0026gt; L(M), R(M); rep(i,0,M) { i64 l, r; cin \u0026gt;\u0026gt; l \u0026gt;\u0026gt; r; L[i] = lower_bound(all(A), l) - begin(A); R[i] = upper_bound(all(A), r) - begin(A); } vector\u0026lt;vector\u0026lt;pair\u0026lt;i64, i64\u0026gt;\u0026gt;\u0026gt; mat(N); rep(i,0,M) { if(L[i] \u0026lt; R[i]) { mat[L[i]].push_back({ R[i], i }); } } vector\u0026lt;pair\u0026lt;i64, i64\u0026gt;\u0026gt; P; rep(i,0,N) { if(mat[i].size() == 0) continue; sort(all(mat[i])); for(i64 j = mat[i].size(); j --\u0026gt; 1;) { int nl = mat[i][j - 1].first; int nr = mat[i][j].first; if(nl \u0026lt; nr) { mat[nl].push_back({ nr, mat[i][j].second }); P.push_back({ mat[i][j - 1].second, mat[i][j].second }); } } } reverse(all(P)); vector\u0026lt;i64\u0026gt; sum(N + 1, 0); vector\u0026lt;i64\u0026gt; ans(M); rep(i,0,N) { if((B[i] + sum[i]) % 2 == 1) { if(mat[i].size() == 0) { cout \u0026lt;\u0026lt; -1 \u0026lt;\u0026lt; endl; return 0; } i64 r = mat[i].front().first; i64 idx = mat[i].front().second; ans[idx] = true; sum[i]++; sum[r]--; } sum[i + 1] += sum[i]; } for(auto p: P) { ans[p.first] ^= ans[p.second]; } vector\u0026lt;i64\u0026gt; res; rep(i,0,M) { if(ans[i]) res.push_back(i); } cout \u0026lt;\u0026lt; res.size() \u0026lt;\u0026lt; endl; rep(i,0,res.size()) { cout \u0026lt;\u0026lt; res[i] + 1 \u0026lt;\u0026lt; \u0026quot; \\n\u0026quot;[i + 1 == res.size()]; } }  〆 ","id":2,"section":"posts","summary":"ABC155-F Perils in Parallel - kotatsugameの日記を読んだときのメモです. AtCoder F - Perils in Parallelを$\\mathbb{F}_2$上の行列として考えて解","tags":null,"title":"ABC155 F Perils in ParallelをF_2の行列で解く","uri":"https://niuez.github.io/2020/02/abc155-f/","year":"2020"},{"content":"Tarjan\u0026rsquo;s off-line LCAを書いてみたので, その時のメモです.\nネタバレ注意\nNo.898 tri-βutree - yukicoder のちょっとしたネタバレが含まれます\u0026hellip;\nTarjan\u0026rsquo;s off-line LCA(lowest common ancestors)は, LCAをoff-lineで$O((N + Q) \\alpha (N))$で求めるアルゴリズムです. ($\\alpha$は逆アッカーマン関数)\nTarjan\u0026rsquo;s off-line lowest common ancestors algorithm - Wikipedia\nDFSの帰りがけに, Union Findで木の辺をuniteしていく. すると, Union Findで表現している集合は, いまたどっている頂点とのLCAが同じになる頂点の集合になります.\n具体例はこんな感じ. いま頂点$6$を見ているとします. 二重線はまだつなげていない辺です.\n緑の集合は, 頂点$6$とのLCAが頂点$0$である集合です. また, 青の集合は, 頂点$6$とのLCAが頂点$4$である集合です.\nDFSの戻りってこういうことできるんだなあ\n実装 注意点はクエリを処理するタイミングで, LCAを求めたい頂点２つのどちらもがdfsされた時であること(なのでans == -2を挟んでいる)\n#include \u0026lt;vector\u0026gt; #include \u0026lt;iostream\u0026gt; #include \u0026lt;set\u0026gt; using namespace std; struct union_find { vector\u0026lt;int\u0026gt; par; vector\u0026lt;int\u0026gt; rank; union_find(int n) : par(n) , rank(n) { for(int i = 0;i \u0026lt; n;i++) par[i] = i; } int root(int i) { return par[i] == i ? i : par[i] = root(par[i]); } /* unite x, y return parent */ int unite(int x,int y) { x = root(x); y = root(y); if(x == y) return -1; if(rank[x] \u0026lt; rank[y]) { par[x] = y; return y; } else { par[y] = x; if(rank[x] == rank[y]) rank[x]++; return x; } } }; using i64 = long long; struct tarjans_offline_lca { using E = pair\u0026lt;int, i64\u0026gt;; vector\u0026lt;vector\u0026lt;E\u0026gt;\u0026gt; G; vector\u0026lt;int\u0026gt; ance; union_find uf; vector\u0026lt;i64\u0026gt; weight; vector\u0026lt;pair\u0026lt;int, int\u0026gt;\u0026gt; query; vector\u0026lt;vector\u0026lt;pair\u0026lt;int, int\u0026gt;\u0026gt;\u0026gt; q; vector\u0026lt;int\u0026gt; ans; tarjans_offline_lca(int n): G(n), ance(n), uf(n), weight(n), q(n) {} void add_edge(int a, int b, i64 w) { G[a].push_back({ b, w }); G[b].push_back({ a, w }); } void add_query(int a, int b) { int i = query.size(); query.push_back({ a, b }); q[a].push_back({ b, i }); q[b].push_back({ a, i }); } void dfs(int v, int f, i64 W) { ance[v] = v; weight[v] = W; for(auto e: G[v]) { int u = e.first; i64 w = e.second; if(f == u) continue; dfs(u, v, w + W); uf.unite(u, v); ance[uf.root(v)] = v; } for(auto e: q[v]) { int u = e.first; int i = e.second; if(ans[i] == -1) ans[i] = -2; else if(ans[i] == -2) ans[i] = ance[uf.root(u)]; } } void offline_lca(int root) { ans.assign(query.size(), -1); dfs(root, -1, 0); } };  使用例です. $N = 10^5$, LCAのクエリ数$Q = 3 * 10^5$で196msならいいんじゃない？ #426438 No.898 tri-βutree - yukicoder\nHLDが速いんじゃ HLDなんでこんなに速いんですかね. $O(N + Q \\log N)$のはずなんですが\u0026hellip; 100ms #426441 No.898 tri-βutree - yukicoder\nしめ クエリを二回見てるのがダメなんですかね\u0026hellip; LCAやるときはHLDでいいでしょう\u0026hellip;\nでも, DFS帰りがけがかなり面白い. どこかで使えるといいな\n","id":3,"section":"posts","summary":"Tarjan\u0026rsquo;s off-line LCAを書いてみたので, その時のメモです. ネタバレ注意 No.898 tri-βutree - yukicoder のちょっとしたネタバレが含まれます\u0026hellip; Tarjan\u0026rsquo;s off-line LCA(lowest","tags":["DFS","LCA","Tree"],"title":"Tarjan's off-line LCA の実装メモと速度","uri":"https://niuez.github.io/2020/02/tarjans_offline_lca/","year":"2020"},{"content":"移植テストです\n書いて置かないと頭に置いておけない気がしたのでメモを残す. 間違ってたらごめん\nこれについて気になったので\nメビウス関数とかを導入するとより形式的に約数とかを扱えるようになるのかなあ\n\u0026mdash; Niuez (@xiuez) January 22, 2020  概要  約数畳み込み メビウス関数 メビウスの反転公式(約数畳み込みの逆操作) 約数畳み込みと逆約数畳み込みのアルゴリズム $O(A \\log{\\log A})$ 最大公約数の扱い 集合の扱い AGC038C LCMsの解き方  ネタバレあるので気をつけてください\n約数畳み込み 関数$f(n)$に対する約数畳み込みとは,\n$\\begin{eqnarray} g(n) = \\sum_{ d | n } f(d) \\end{eqnarray}$\nあとで解説しますが, 方針としてはこの畳み込んだ後の$g(n)$を問題を解けるように定義してやることでGCDを綺麗に扱うことができます.\nメビウス関数 実際に$g(n)$を定義してみます. 一番有名なのは$g(n) = \\delta(n, 1)$です. $\\delta(n, 1)$はクロネッカーのデルタです. このとき,\n$\\begin{eqnarray} g(n) = \\delta(n, 1) = \\sum_{ d | n } f(d) \\end{eqnarray}$\nを満たす$f(n)$はメビウス関数と呼ばれ, $\\mu(n)$と書きます.(メビウス関数 - Wikipedia)\nメビウスの反転公式(約数畳み込みの逆操作) 上の式のままだと, $f(n)$を導くのは困難です. ここで登場するのがメビウスの反転公式です. これは, 約数畳み込みの逆操作に当たります.\n$$ \\begin{eqnarray} g(n) \u0026amp;=\u0026amp; \\sum_{ d | n } f(d) \\\\\nf(n) \u0026amp;=\u0026amp; \\sum_{ d | n } g(d) \\mu(\\frac{n}{d}) \\end{eqnarray} $$\nこれで$g(n)$を定義してから反転公式を適用することで$f(n)$を導くことができます.\n約数畳み込みと逆約数畳み込みのアルゴリズム 約数畳み込みとその逆はnoshi91さんが計算量$O(A \\log{\\log A})$で計算するアルゴリズムの記事を紹介しています.\nhttp://noshi91.hatenablog.com/entry/2018/12/27/121649\n逆約数畳み込みの実装例\ntemplate \u0026lt;class T\u0026gt; void inverse_divisor_transform(vector\u0026lt;T\u0026gt; \u0026amp;a) { int n = a.size(); vector\u0026lt;bool\u0026gt; sieve(n, true); for (int p = 2; p \u0026lt; n; ++p) { if (sieve[p]) { for (int k = (n - 1) / p; k \u0026gt; 0; --k) { sieve[k * p] = false; a[k * p] -= a[k]; } } } }  最大公約数の扱い 自然数$n, m$に対して,\n$\\begin{eqnarray} \\sum_{d | n, d | m} f(d) \\end{eqnarray}$\nを考えると,\n$$ \\begin{eqnarray} \\sum_{d | n, d | m} f(d) \u0026amp;=\u0026amp; \\sum_{d | \\gcd(n, m)} f(d) \\\\\n\u0026amp;=\u0026amp; g(\\gcd(n, m)) \\end{eqnarray} $$\nとなり, $\\gcd(n, m)$に対する操作ができます. 例えば, $f(n) = \\mu(n), g(n) = \\delta(n, 1)$とすると, $g(\\gcd(n, m))$は,「$n, m$が互いに素であれば$1$, そうでなければ$0$」となり, 互いに素かどうかの判定ができます.\n集合の扱い 例えば, $c_m(d) = [d | m$]という関数($d$が$m$を割り切るなら$1$, そうでなければ$0$)を考えると,\n$$ \\sum_{d | n, d | m} f(d) = \\sum_{ d | n } f(d) c_m(d) $$\nと変形できます.\nこれを応用します. 自然数の集合$S$ を考え, $c(d) = \\sum_{m \\in S} c_m(d)$とすると,\n$$ \\begin{eqnarray} \\sum_{d | n} f(d) c(d) \u0026amp;=\u0026amp; \\sum_{m \\in S}\\sum_{d | n} f(d) c_m(d) \\\\\n\u0026amp;=\u0026amp; \\sum_{m \\in S} g(\\gcd(n, m)) \\end{eqnarray} $$\nとなります.\n$f(n) = \\mu(n), g(n) = \\delta(n, 1)$を考えてみると, 「集合$S$の中に$n$と互いに素な要素の数」を計算しています.\nAGC038C LCMsを解く AGC038 C - LCMs $lcm(x, y) = x (\\frac{y}{\\gcd(x, y)})$と変形します. 約数畳み込みを使う方針でやると, この$(\\frac{y}{\\gcd(x, y)})$が最後に来てほしい気持ちになります. $g(n) = \\frac{1}{n}$と置くと,\n$$ \\begin{eqnarray} \\frac{y}{\\gcd(x, y)} \u0026amp;=\u0026amp; y \\cdot g(\\gcd(x, y)) \\\\\n\u0026amp;=\u0026amp; \\sum_{d | gcd(x, y)} f(d) y \\\\\n\u0026amp;=\u0026amp; \\sum_{d | x, d | y} f(d) y \\\\\n\u0026amp;=\u0026amp; \\sum_{d | x} f(d) s_y(d) \\end{eqnarray} $$\nここで$s_y(d)$を「$d$が$y$を割り切るなら$y$, そうでなければ$0$」としました.\n応用して, 自然数の集合$S$ を考え, $s(d) = \\sum_{m \\in S} s_m(d)$とすると,\n$$ \\begin{eqnarray} \\sum_{d | x} f(d) s(d) \u0026amp;=\u0026amp; \\sum_{y \\in S}\\sum_{d | x} f(d) s_y(d) \\\\\n\u0026amp;=\u0026amp; \\sum_{y \\in S} y \\cdot g(\\gcd(x, y)) \\end{eqnarray} $$\nと計算できて, これに$x$を掛けると「集合$S$の中の各要素と$x$の最大公約数の和」を計算できました.\n計算量は, $O(A \\log{\\log A} + N \\sqrt A)$です.\nC - LCMs の僕の提出\nソースコード\n#include \u0026lt;bits/stdc++.h\u0026gt; using namespace std; using i64 = long long; #define rep(i,s,e) for(i64 (i) = (s);(i) \u0026lt; (e);(i)++) /* modint */ /* IO(niu::fin, niu::fout) */ const i64 MOD = 998244353; using fp = modint\u0026lt;MOD\u0026gt;; #include \u0026lt;bits/stdc++.h\u0026gt; using namespace std; using i64 = long long; template \u0026lt;class T\u0026gt; void inverse_divisor_transform(vector\u0026lt;T\u0026gt; \u0026amp;a) { int n = a.size(); vector\u0026lt;bool\u0026gt; sieve(n, true); for (int p = 2; p \u0026lt; n; ++p) { if (sieve[p]) { for (int k = (n - 1) / p; k \u0026gt; 0; --k) { sieve[k * p] = false; a[k * p] -= a[k]; } } } } constexpr i64 A = 1e6 + 1; int main() { std::vector\u0026lt;fp\u0026gt; f(A); rep(d,1,A) { f[d] = fp(d).pow(MOD - 2); } inverse_divisor_transform(f); i64 N; niu::fin \u0026gt;\u0026gt; N; vector\u0026lt;fp\u0026gt; sum(A); fp ans = 0; rep(i,0,N) { int x; niu::fin \u0026gt;\u0026gt; x; fp res = 0; for(int d = 1; d * d \u0026lt;= x; d++) { if(x % d == 0) { res += f[d] * sum[d]; sum[d] += fp(x); if(x / d != d) { res += f[x / d] * sum[x / d]; sum[x / d] += fp(x); } } } ans += res * fp(x); } niu::fout \u0026lt;\u0026lt; ans.value() \u0026lt;\u0026lt; \u0026quot;\\n\u0026quot;; }  ","id":4,"section":"posts","summary":"移植テストです 書いて置かないと頭に置いておけない気がしたのでメモを残す. 間違ってたらごめん これについて気になったので メビウス関数とかを導入す","tags":["Divisor","Transform","Mobius","GCD","LCM"],"title":"約数畳み込みを使って最大公約数と集合をうまく扱うメモ","uri":"https://niuez.github.io/2020/02/divisor_transform_memo/","year":"2020"},{"content":"はじめまして\nいつはてなブログが消えてもおかしくない気がするので, 僕のはてなブログからこっちに移してこようかなと考えてます.\nテスト期間真っ最中なので春休みに入ったらやろうかな.\nにう\n","id":5,"section":"posts","summary":"はじめまして いつはてなブログが消えてもおかしくない気がするので, 僕のはてなブログからこっちに移してこようかなと考えてます. テスト期間真っ最中","tags":null,"title":"First","uri":"https://niuez.github.io/2020/02/first/","year":"2020"},{"content":"この土日のメモです. SAとLCPのお気持ちをまとめたくなっただけ. 間違ってたらごめん\n 文字列アルゴの勉強する気が起きないたった一つの理由: Rolling Hash— νιυεζ (@xiuez) 2019年12月13日\n これをやめたいので, 手始めにSuffix Arrayを使った文字列検索をやってみようかなというのが今回の主題\n概要  SA-ISでSuffix Arrayを構築$ O(|S|)$ LCP配列の構築$ O(|S|)$ LCPによるSuffix同士のLCPをSparse Tableで構築$ O(|S| \\log{|S|})$, クエリ$ O(1)$ Suffix Arrayの二分探索で文字列検索を$ O(|T| log{|S|})$ Suffix ArrayとLCPの二分探索で文字列検索を構築$ O(|S|)$, クエリ$ O(|T| + \\log{|S|})$  の実装をやってみました. このときのメモを残しておきたいと思います.\n各用語の説明はここではしません\u0026hellip; 他の記事や, 蟻本 - Amazonを参考に.\nSA-IS Suffix Arrayの実装は蟻本にも載っていますが, そこまで早くありません\u0026hellip; SA-ISというアルゴリズムが早いらしいのでこれを実装します.\nSA-ISの理解には, この記事がとても参考になりました. とてもわかりやすい記事です.\nSA-IS 法のメモ - まめめも\nSA-ISの実装はyosupoさんのコードを見ました.\n僕が書いたSA-ISのコードはこれです.\nSubmitted\n メモリを使い回す(resizeの回数を減らしてメモリを使いまわしても, assignが割と早くてこれが非自明) push_backをなくす 入出力の早いライブラリを使うともっと早くなります  実はSA-ISの論文に実装が載っていてそれがとても速いです. ぜひ参考にしてみてください.\n以下, 文字列SのSuffix ArrayをSAとします. Sの辞書順でi番目に小さいsuffixをSuf[i] := S[SA[i]\u0026hellip;]とします.\nLCP(Longest Common Prefix) LCP配列は, Suffix Arrayで隣り合ったSuffix(つまり, Suf[i]とSuf[i + 1])の最長共通接頭辞を求めた配列です. Kasai's Algorithmを用いて$ O(|S|)$で構築できます.\nLCPの理解は以下の記事がわかりやすいです. 蟻本にもあるはず.\nLCP配列 (Kasai’s algorithm)\n例は, 接尾辞配列(Suffix-Array) | Luzhiled’s memo がわかりやすいです.\n僕の実装は先頭に無(空配列)があるので, 以下のようになります.\ni :lcp 0 : 0 1 : 0 a 2 : 1 abra 3 : 4 abracadabra 4 : 1 acadabra 5 : 1 adabra 6 : 0 bra 7 : 3 bracadabra 8 : 0 cadabra 9 : 0 dabra 10: 0 ra 11: 2 racadabra  任意のsuffix同士のLCP 上の例で, i = 2, abraと, j = 5, adabraのLCPを求めるとすると, 3, 4, 5のlcpの最小値である1がその答えになります.\nSuffix Arrayで, indexが $ i$ のsuffixと $ j$ のsuffixのLCPは, $ [i + 1, j + 1)$ 間のlcpの最小値になります.\nなので, lcpをSparse Tableに載せると構築 $ O(|S| \\log{|S|})$, クエリ$ O(1)$で処理できます.\nSuffix Arrayで文字列検索 文字列SのSuffix Array SAを使って, Sの中に文字列Tがあるかどうかを二分探索で処理できます. これは, Suffix Arrayによって各suffixがソートされているのを利用しています.\n計算量は$ O(|T| \\log{|S|})$です. AOJの提出コード\ncin \u0026gt;\u0026gt; t; int L = 0; int R = sa.size(); while(R - L \u0026gt; 1) { int M = (L + R) \u0026gt;\u0026gt; 1; if(s.substr(sa[M], t.size()) \u0026amp;lt;= t) { L = M; } else { R = M; } } cout \u0026amp;lt;\u0026amp;lt; (s.substr(sa[L], t.size()) == t) \u0026amp;lt;\u0026amp;lt; endl;  これがかなりはやい なんでだろう\nSAとLCPで文字列検索 この二分探索はさらに高速化できます. suffixとTの比較を最小限にすることで, $ O(|T| + \\log{|S|})$を達成します.\n具体的には, suf[L]とTのLCPを常に持ちながら二分探索をします. このLCPをLlcpとします. M = (L + R) / 2として, suf[L]とsuf[M]のLCPを求めて, nlcpとします. nlcpは先に書いたとおり, Sparse Tableで求めることができます. 次にLlcpとnlcpを比較します.\n Llcp \u0026lt; nlcpのとき  以下の例で考えてみます. (Suffix Arrayではありませんが, 複数の文字列を辞書順にソートしたという意味で同じです)\nT = ad L : aaa aaab aaac M : aac aacc ba R : Llcp = LCP(aaa, ad) = 1 // \u0026quot;a\u0026quot;aa, \u0026quot;a\u0026quot;dなので nlcp = LCP(aaa, aac) = 2 // \u0026quot;aa\u0026quot;a, \u0026quot;aa\u0026quot;cなので  Tは辞書順でsuf[T]以上ということがわかっているので, Llcp \u0026lt; nlcpより, Tとsuf[M]のLCPはLlcpであり, Tは辞書順でsuf[M]以上です. なので, Llcpはそのままで, L = Mとします.\n Llcp  nlcpのとき  T = aaac L : aaa aaab aaac M : aac aacc ba R : Llcp = LCP(aaa, aaac) = 3 // \u0026quot;aaa\u0026quot;, \u0026quot;aaa\u0026quot;cなので nlcp = LCP(aaa, aac) = 2 // \u0026quot;aa\u0026quot;a, \u0026quot;aa\u0026quot;cなので  Tとsuf[M]のLCPはnlcpであり,Tは辞書順でsuf[M]未満です. なので, Llcpはそのままで,R = M`とします.\n Llcp = nlcpのとき  T = aacc L : aaa aaab aaac M : aac aacc ba R : Llcp = LCP(aaa, aacc) = 2 // \u0026quot;aa\u0026quot;a, \u0026quot;aa\u0026quot;ccなので nlcp = LCP(aaa, aac) = 2 // \u0026quot;aa\u0026quot;a, \u0026quot;aa\u0026quot;cなので  このときは, Tとsuf[M]の辞書順の関係がわからないので比較をします. このとき, LCPの部分は一致していることがわかっているので比較をしなくてよいです. 比較をした後, Llcpを比較をした時の計算結果を利用して更新します.\nLlcpは探索中, 単調増加します. なので, 文字列の比較が全体で$ O(|T|)$しかされません. これにより, 計算量が改善されます.\n実際にコードを示します.\nstd::pair\u0026amp;lt;int, int\u0026gt; get_lcp(const std::vector\u0026amp;lt;T\u0026gt;\u0026amp;amp; t, int si, int offset) { int i = offset; si += offset; while(i \u0026amp;lt; t.size() \u0026amp;amp;\u0026amp;amp; si \u0026amp;lt; N) { if(t[i] != str[si]) { return { i, t[i] - str[si] }; } i++; si++; } return { i, 0 }; } std::pair\u0026amp;lt;int, int\u0026gt; search(const std::vector\u0026amp;lt;T\u0026gt;\u0026amp;amp; t) { int L = 0; int R = N + 1; int Llcp = 0; while(R - L \u0026gt; 1) { int M = (L + R) \u0026gt;\u0026gt; 1; int nlcp = st.query(L + 1, M + 1); if(Llcp \u0026amp;lt; nlcp) { L = M; } else if(Llcp \u0026gt; nlcp) { R = M; } else { auto p = get_lcp(t, sa[M], Llcp); if(p.second \u0026gt;= 0) { L = M; Llcp = p.first; } else if(p.second \u0026amp;lt; 0) { R = M; } } } return { Llcp, L }; }  これで早くなるはず\u0026hellip;!\nAizu Online Judge\n5倍遅くなった\u0026hellip;\nSparse Tableの構築が重すぎる $ O(|S| \\log{|S|})$ 流石に重い\u0026hellip; 改善したい\nSparse Tableを使わない方法で改善 二分探索だけならSparse Tableである必要はありません. Segment Treeを使います. 二分探索で最小値を求めたい区間は必ず[L, (L + R) / 2)に対応できます. なので, 二分探索するときに, Segment Treeのノードを降りていくようにすると 構築$ O(|S|)$で二分探索ができるようになります.\nコードはこんな感じ\n... ... seg_n = 1; while(seg_n \u0026amp;lt; N + 1) seg_n \u0026amp;lt;\u0026amp;lt;= 1; seg.resize(seg_n * 2, 1e9); for(int i = 0;i + 1 \u0026amp;lt; N + 1;i++) { seg[i + seg_n - 1] = lcp[i + 1]; } for(int i = seg_n - 1; i --\u0026gt; 0;) { seg[i] = std::min(seg[(i \u0026amp;lt;\u0026amp;lt; 1) + 1], seg[(i \u0026amp;lt;\u0026amp;lt; 1) + 2]); } } std::pair\u0026amp;lt;int, int\u0026gt; get_lcp(const std::vector\u0026amp;lt;T\u0026gt;\u0026amp;amp; t, int sa_i, int offset) { if(sa_i \u0026gt; N) return { offset, -1 }; int i = offset; int si = sa[sa_i] + offset; while(i \u0026amp;lt; t.size() \u0026amp;amp;\u0026amp;amp; si \u0026amp;lt; N) { if(t[i] != str[si]) { return { i, t[i] - str[si] }; } i++; si++; } return { i, 1 }; } std::pair\u0026amp;lt;int, int\u0026gt; search(const std::vector\u0026amp;lt;T\u0026gt;\u0026amp;amp; t) { int L = 0; int R = seg_n; int Llcp = 0; int j = 0; while(R - L \u0026gt; 1) { int M = (L + R) \u0026gt;\u0026gt; 1; int nlcp = seg[(j \u0026amp;lt;\u0026amp;lt; 1) + 1]; if(nlcp == 1e9) { j = (j \u0026amp;lt;\u0026amp;lt; 1) + 1; R = M; } else if(Llcp \u0026amp;lt; nlcp) { j = (j \u0026amp;lt;\u0026amp;lt; 1) + 2; L = M; } else if(Llcp \u0026gt; nlcp) { j = (j \u0026amp;lt;\u0026amp;lt; 1) + 1; R = M; } else { auto p = get_lcp(t, M, Llcp); if(p.second \u0026gt;= 0) { j = (j \u0026amp;lt;\u0026amp;lt; 1) + 2; L = M; Llcp = p.first; } else if(p.second \u0026amp;lt; 0) { j = (j \u0026amp;lt;\u0026amp;lt; 1) + 1; R = M; } } } return { Llcp, L }; }  Aizu Online Judge\nこれでも最初の二分探索に勝てませんでした\u0026hellip; なんでだろう でもこれでもかなり速いです.\nしめ FM-indexとかやってみたくなりました\n","id":6,"section":"posts","summary":"この土日のメモです. SAとLCPのお気持ちをまとめたくなっただけ. 間違ってたらごめん 文字列アルゴの勉強する気が起きないたった一つの理由: Rolling H","tags":[],"title":"Suffix Array と LCP と 文字列検索の実装をした","uri":"https://niuez.github.io/2019/12/203739/","year":"2019"},{"content":"この記事は「データ構造とアルゴリズム Advent Calendar 2019」 14日目の記事です. 13日目は@ajalabさんのRun-Length FM-Index - koki, 15日目は@minaminaoさんのMerkle Patricia Tree まわりです.\ntoptreeとは toptreeは今年競プロ界隈で話題になった動的木を扱うデータ構造の一つです. link-cut treeも同じ動的木を扱うデータ構造ですが, 機能だけを見ればその完全上位互換です.\ntoptreeは, 木を動的に扱うデータ構造です. [cs/0310065] Maintaining Information in Fully-Dynamic Trees with Top Treesを読みました.\ntoptree自体については半年くらい前に自分が書いた記事があります.\nToptree 導入編 - niuez’s diary\n上の記事をまとめると\n 基本的には, 平衡二分探索木(Splay Tree) 葉には辺を表すノード(Edge Node) 1頂点を共有する２つの辺をマージして新しくできた辺を平衡二分探索木の節とする(Compress \u0026amp; Rake)     二分木だけでは列しか管理できないので, 二分木ともう一つの子を管理する(Rake Node)    というあたりです. この形を保持しながらsplay treeの回転を行い各クエリの計算量を償却$ O(\\log N)$を達成しています.\n例えば,\n $ \\mathtt{link}$: ある2頂点間を辺で結ぶ $ \\mathtt{cut}$: ある2頂点間を結んでいる辺をなくす パス: ある木の2頂点を結ぶパスについてのクエリを処理する  辺の重みの総和 辺の重みを$ +x$する など...   木全体に対するクエリ  木に含まれる辺の重みを$ +x$する 木の頂点の重みの総和 木の直径 ある頂点からの最遠点距離   toptree上の二分探索  木の中心 木の重心 パス$ x, \\cdots, y$上で$ x$から$ y$に向かって$ d$だけ進んだ場所にある頂点 *1    というクエリが処理できます. 最強っぽい.\nこれを実装したのがこれです. めっちゃ大変でした. niuez/toptree-rust\n動的木上の最小シュタイナー木 10月に僕の作問した問題がyukicoderで木上クエリコンとして出題されました. このときに全問正解を(意図的に)阻止した問題がこれです.\nNo.902 Query ζone - yukicoder\n辺に正の重みが与えられている木の形が動的に変わっていくなかで, 頂点$ v_0, \\cdots, v_{k-1}$の最小シュタイナー木の重みを答えるクエリを処理しなければなりません.\nサンプルを図にしてみます.\nサンプルの2個目のクエリのとき, 木は以下のような形をしています. この木に関して, 頂点0, 4, 6を頂点の部分集合とする最小シュタイナー木の重みは20です.\n  サンプルの4個目のクエリのとき, 木は以下のような形をしています. この木に関して, 頂点0, 4, 6を頂点の部分集合とする最小シュタイナー木の重みは27です.\n  この問題は, toptreeに載せることで解くことができます. 今回はその解説をしたいと思います.\nここから先, 各クエリで最小シュタイナー木に含めなければならない頂点を赤い頂点と表現することにします.\nアルゴリズム toptreeでは上でも述べたように, 1頂点を共有する２つの辺をマージして新しくできた辺を平衡二分探索木の節とします. 今回の問題で考えられる, マージされる前の辺の状態は2通りのみです.\n 赤い頂点を1個以上含んでマージされた辺     赤い頂点を一度も含んでいない辺    以下のような場合を考えそうになりますが, これは$ \\mathbb{inter}=0$とすると, １つ目のパターンと同じになります.\n  辺の端点の色は, マージするときに考えます. つまり, マージの方法は 左側の辺の状態(2通り) * 右側の辺の状態(2通り) * 共有している1頂点の色(2通り) = 8通りです\nマージの計算方法(Compress) 以下の通りです.\n          このパターンは頂点が赤でも黒でも同じです\n何か足りない このパターンだけでは, $ \\mathbb{inter}$は作られません. どういうことでしょう\u0026hellip;? 上でも述べたとおり, toptreeでは2通りのマージ方法があります. そのもう一つのマージ方法(Rake)では以下のパターンで$ \\mathbb{inter}$を発生させます.\n  他のパターンは上と同じように計算することができます.\nこれをちゃんと実装すると以下のように解くことができます.\n#383717 No.902 Query ζone - yukicoder\n20行目からの関数が, 上で述べたCompressのマージの計算をしています. その下にRakeの計算もありますね.\nしめ 今年はtoptreeに夢中な一年でした. 来年はどうなるでしょうか.\n*1:jumpと呼ばれることが多い   ","id":7,"section":"posts","summary":"この記事は「データ構造とアルゴリズム Advent Calendar 2019」 14日目の記事です. 13日目は@ajalabさんのRun-Length FM-Index - koki, 15日目は@m","tags":[],"title":"動的木上の最小シュタイナー木をtoptreeで解く","uri":"https://niuez.github.io/2019/12/000036/","year":"2019"},{"content":"僕が木上クエリコンで出題した問題で使った手法です.\nNo.899 γatheree - yukicoder\nアルゴリズム 例\n  Euler TourをBFSで行います. すると, Euler Tourの列は\n0 1 2 3 4 5 6 7 8 9 10 11 12 13 14  になります. ここで, BFSは深さが浅い順に頂点を見ることに注目すると,\n 頂点0の部分木の中で, 頂点0から距離1にある頂点  0 [1 2] 3 4 5 6 7 8 9 10 11 12 13 14   頂点0の部分木の中で, 頂点0から距離2にある頂点  0 1 2 [3 4 5 6] 7 8 9 10 11 12 13 14  また同様に\n 頂点1の部分木の中で, 頂点0から距離1にある頂点  0 1 2 [3 4] 5 6 7 8 9 10 11 12 13 14   頂点1の部分木の中で, 頂点0から距離2にある頂点  0 1 2 3 4 5 6 [7 8 9 10] 11 12 13 14  つまりBFS Euler Tourは, 深さを同じくする頂点を列の区間に落とし込むことができます.\n実装はこんな感じ(この例では, 距離2までの頂点を記録しています)\ni64 N; cin \u0026gt;\u0026gt; N; idx.resize(N + 1, -1);//idx[v] := Euler Tourの列での頂点vの位置 L1.resize(N + 1, -1);//距離1にある頂点の列の左端 R1.resize(N + 1, -1);//右端 L2.resize(N + 1, -1);//距離2にある頂点の列の左端 R2.resize(N + 1, -1);//右端 p.resize(N + 1, -1);//親 G.resize(N + 1); for(int i = 0;i \u0026amp;lt; N - 1; i++) { i64 a, b; cin \u0026gt;\u0026gt; a \u0026gt;\u0026gt; b; G[a].push_back(b); G[b].push_back(a); } G[N].push_back(0); queue\u0026amp;lt;i64\u0026gt; que; que.push(N); idx[N] = vec.size(); vec.push_back(N); while(!que.empty()) { i64 v = que.front(); que.pop(); for(auto x: G[v]) { if(idx[x] != -1) continue; que.push(x); idx[x] = vec.size(); vec.push_back(x); p[x] = v; if(L1[v] == -1) L1[v] = idx[x]; R1[v] = idx[x] + 1; i64 pp = p[v]; if(pp != -1) { if(L2[pp] == -1) L2[pp] = idx[x]; R2[pp] = idx[x] + 1; } } }  わりと素直に書ける\n感想 新出で驚いた 典型にしていこうな\n","id":8,"section":"posts","summary":"僕が木上クエリコンで出題した問題で使った手法です. No.899 γatheree - yukicoder アルゴリズム 例 Euler TourをBFSで行います. すると, Euler Tourの列は","tags":[],"title":"BFS Euler Tour","uri":"https://niuez.github.io/2019/10/002503/","year":"2019"},{"content":"Toptree 導入編 - niuez’s diary\n引き続き, toptreeの解説をしていきます.\nLink link(v, w): 頂点vとwを辺vwで結ぶをします.\n場合分けが多すぎるんじゃ\nが, vの次数が0, 1, 2以上で処理が変わり, またwの次数が0, 1, 2以上で処理が変わります. (ちなみに論文はどちらも次数2以上のときのことしか書いてない, 全部書けや)\nまず, expose(v)をした結果はこんな感じに次数で場合分けできます. exposeした後, 次数1のときに右側にvが来るようにします(左にあるときはreverseします)\n  expose(w)をしたときはこんな感じ. exposeした後, 次数1のときに左側にwが来るようにします.\n  vが右側, wが左側なのは, \u0026hellip; - vとw - \u0026hellip;をつなげて \u0026hellip; - v - w - \u0026hellip;としたいからです.\n次に, w側のtoptreeから処理していきます. ここでは, \u0026hellip; - v - w - \u0026hellip;のv - w - \u0026hellip;の部分を作ります.\n  このそれぞれの木の根をv-w-と表すことにして, v側のtoptreeとつなげます. つなげ方は, vの次数によって場合分けです. つなげるとこんな感じ\n  \u0026hellip; - v - w - \u0026hellip;になっていると思います.\nCut cut(v, w): 頂点vとwを結んでいる辺vwを切ります\nlinkの逆操作をすればいいです. soft_exposeを思い出してみましょう.\n  vwは辺なので, 図中の丸vwはCompress Nodeではなく, Edge Nodeのはずです. また, degree(v) \u0026gt;= 2, degree(w) \u0026gt;= 2のパターンを見ると, N_w以下がlinkでのv - w - \u0026hellip;の部分を作るときと形が同じです. まあなので逆操作をするとcutができます.\n記事を分けたの失敗 LinkとCut重いなあと違う記事にしたけど, 図を作ったらそんなに重くなかった\n次はクエリの捌き方を書きます(これは流石に分けないとまずい)\n","id":9,"section":"posts","summary":"Toptree 導入編 - niuez’s diary 引き続き, toptreeの解説をしていきます. Link link(v, w): 頂点vとwを辺vwで結ぶをします. 場合分けが多すぎるんじゃ が,","tags":[],"title":"Toptree - Link \u0026 Cut編","uri":"https://niuez.github.io/2019/08/114511/","year":"2019"},{"content":"みんな日本語記事を待っていたはず\u0026hellip;.!\ntoptreeがどんな感じで動いているのかを書いてみます\n実装はここにあります\nhttps://github.com/niuez/toptree-rust\n0. toptree is なに toptreeはlink-cut treeの上位互換です. 木を切ったりつなげたり, パスのクエリを処理したり, 木上の二分探索ができたりします\n今回はそのベースとなる構造の話です\n1. Compress Rake 木をまとめる ここで言う木は, toptreeが表す木のことです. 曖昧にならないようにこのことをreal treeと呼ぶことにします. (木を木で表現するの文章が曖昧になりがち)\ntoptreeでは, つながっている2つの辺をまとめる操作を繰り返したものを表現した木です. 1つの辺にまとめ上げることでパスを表現します.\nまとめる操作は２つあり, それぞれCompress, Rakeといいます.\n  具体的に こんな感じでまとめていきます\n  このまとめていく操作を木で表現するのがtoptreeです.\nCompress Tree 例えば, a - c - bという一直線のreal treeを扱う時, 辺acとcbをcompressをします. これをtoptreeで表現すると\n  四角は辺を表すノードです. Edge Nodeといいます. toptreeでは, Edge Nodeを葉にします. 丸はcompressした後の辺を表すノードです. Compress Nodeといいます. Compress Nodeが節, Edge Nodeが葉のこの木をCompress Treeといいます. 重要なのは, Compress Treeの根がパスの端点を結ぶ, Compressされた辺を表しているということです. またそのcompressされた辺の端点は必ず次数が1です.\n0 - 1 - 2 - 3 - 4 - 5 というreal treeをtoptreeで表すと, 一例としては以下のようになります.\n  辺の向き付け ここで葉のEdge Nodeの順番がパスの辺の順番になっている点に注意してください.\ntoptreeでは辺の向きに注意して操作しないとダメです. 僕の実装では, 0 - 1 - 2 - 3 - 4 - 5のtoptreeを0 -\u0026gt; 1 -\u0026gt; 2 -\u0026gt; 3 -\u0026gt; 4 -\u0026gt; 5と向き付けると解釈しています. 以後のreal treeの図では向き付けしたものを用います.\ncompress, rakeを, 同じ向きのものをまとめる操作と解釈することにしましょう. すると, compress, rakeを向き付けたreal treeについて改めて考えると以下のようになります.\n  上の具体的にで示したreal treeはこんな感じで向き付けすると同じようにまとめる操作ができるはずです.\n  Rake Tree では一直線ではないreal tree, 例えばこれはどうやってtoptreeにするのでしょうか.\n  ここでrakeを使います.\n  ?????????????????????\n辺14を追加したreal treeをtoptreeにすると\n  ひし形のノードはcompressと同じように察せるはずです. 31と41をrakeしたものを表現しており, ひし形のノードをRake Nodeといいます. また, Rake Nodeが節, Compress Treeの根が葉の木をRake Treeといいます.\n図では, Compress Nodeに今までの左右の子と, 赤の線でつながった子があります. 赤の線でつながった子は, Compress Nodeの右の子とrakeされるノードです.\nこのように3分木にしてreal treeの情報を持ちます.\n具体例のtoptree こんな感じになります 四角はEdge Node, 丸はCompress Node, ひし形はRakeNodeです.\n  Compress Tree(青の点線で囲った部分), Rake Tree(赤の点線で囲った部分)はそれぞれここです\n  Splice  重要なのは, Compress Treeの根がパスの端点を結ぶ, Compressされた辺を表しているということです.\n   この木のtoptreeをもう一度見てみます.\n  0 - 1 - 2がこのtoptreeの主役のパスになっています.\nでも, 3 - 1 - 2を主役にしたいときもあるはずです. それは, 31と01を入れ替えることで達成できます.\n  0 - 1 - 3にを主役にしたいときもあるはずです. それは, 31と12の向きを反転させてから入れ替えることで達成できます.\n  この, Rake Treeの葉のノードと, Compress nodeの子を入れ替えてCompress Nodeの表すパスを変える操作をspliceといいます.\nSplay Splay Treeを知っていますか? wikipediaを見て\nSplay Treeでは, splayという木を回転させてノードを根に持ってくるという操作をします. まあwikipediaみて toptreeで扱っている木は, 葉木です. 葉はsplayできないことに注意しましょう.\nHandle spliceをするとパスを変形できることはわかりましたが, 具体的にどのノードをspliceすると良いのでしょうか?\nそれを示すのがhandleという概念です. handleは各頂点に対して割り振られるもので, toptree上のCompress/Edge Nodeが割り振られます.\n具体的には, 下のルールで構成します.\n Compress Node abの左右の子がac, cbのとき, 頂点cのhandleはCompress Node ab Compress/Edge Node abの親が いない(toptreeの根): 頂点a, bのhandleはCompress Nodeab それ以外(Rake Treeの葉になっている): 頂点aのhandleはCompress Node ab  具体例を見たほうが早い気がします.\n  頂点0, 5はルール2., 8, a, b, cはルール3., それ以外は1.です.\n今はとりあえずこういうものとしておくのがいいと思います.(あとで大活躍します.)\nまた頂点vに対して, N_vをvのhandleのNodeとします. (上の図で言えばN_2はtoptreeの根です)\nExpose exposeという操作を導入したいと思います. (これが超本質) 任意の頂点vのhandleをtoptreeの根にするのがexposeです.\n先にどうやってexposeするか書いてしまいます.\nexpose(v)\n N_vをCompress Tree上でsplayする N_vの親が   いない: N_vはtoptreeの根になったのでexpose終了 Compress Node: そのCompress Nodeをnとおく Rake Node: そのRake Nodeをrとおく, rをRake Tree上でsplayし, rの親をnとおく(nはCompress Nodeになります)  nをCompress Tree上でsplay nの左のノードとN_vを入れ替える N_vがEdge Nodeのとき, N_vをnにする 1に戻る.  1. splay(N_v) N_vの属しているCompress Tree上でN_vを根にします.\n2. これがちょっとむずかしいです.\n親がいない場合は目的達成なので終了です.\nCompress Nodeの場合, こんな状態です.\n  Rake Nodeの場合, 例えばこんな状態です.\n  splay(r)をすると, こうなります.\n  3. splay(n) 4で行う操作を簡単にするために行います. なんで簡単になるかはsoft_exposeで解説したいと思います.\n4. splice(N_v) 入れ替えます.\n    5. これは何かというと, N_vがEdge Nodeのとき, spliceするとvのhandleの位置が変わります. これに対応するためです.\n6. これで, N_vをtoptreeの根にすることができます.\nSoft Expose soft_exposeは任意の頂点v, u間のパスのCompress Node vuを作る操作です！(やっとここまできた) こんな形にtoptreeを変形します.\n  (8/5 なんか頭悪い画像になっていたので修正しました)\n手順を先に言ってしまいます\nsoft_expose(v, u)\n expose(v) N_vとN_wが   同じ: toptreeの根はvuかuvなので, uvであれば反転する. soft_exposeおわり 違う: 続く  N_vをguardする(????) expose(w) N_vのguardを外す N_vから見てN_uが右側なら, 反転させる. おわり  toptreeの根をguardするとは, splay操作があってもtoptreeの根を変えさせないようにすることです. これは, N_vをtoptreeの根にした後, N_vの左側にN_wを持ってくる必要があり, N_vが根であり続ける必要があるからです.\nguardされているときのspliceの操作が少し違います.\nnの親がguardされていて, 親から見て左側にある場合, spliceはnの左の子と交換しないといけません.\n  しかし, 親から見て右側にある場合, spliceはnの左の子と交換しないといけません.\n  これはtoptreeの, 葉がパスの辺の順番になっているルールに違反するからです.(toptree壊れる)\nPath Query soft_exposeができるようになると, パスに関するクエリを処理することができます. パスの長さとか, パス中の辺の長さの最大値とかです.\n各ノードに情報をもたせて, セグ木みたいに左の子の情報と右の子の情報を演算するみたいな感じです. これをすると, soft_expose(v, w)をしてvwを見た時にパスv-wについての演算結果が求まるはずです. やったね.\nひとまず終了\u0026hellip; link, cut, select, 各種クエリとかは後日にします\u0026hellip; 疲れた\u0026hellip;\nToptree - Link \u0026amp; Cut編 - niuez’s diary link cutかいた\ntop tree 概要 - noshi91のメモ\n僕が書くのサボった厳密な話をnoshi91さんが書いています こちらも読んでください\n","id":10,"section":"posts","summary":"みんな日本語記事を待っていたはず\u0026hellip;.! toptreeがどんな感じで動いているのかを書いてみます 実装はここにあります https://github.com/niuez/toptree-rust 0. toptree is なに","tags":[],"title":"Toptree 導入編","uri":"https://niuez.github.io/2019/08/191420/","year":"2019"},{"content":"読者層が限定されすぎていませんか？\nLink Cut Treeを書いたことがない人はこちら！\nLink-Cut 木 - ei1333の日記\n部分木クエリについてはこちら！\nLink Cut Treeで部分木の情報を管理する - beet's soil\n最遠点クエリについてはこちら！\nLink-Cut木と最遠点クエリ - ei1333の日記\nえ〜っと, 多分toptreeが書けました. 多分! verifyしたいんですが, Rustのバージョンで困っています\u0026hellip;\n実装 論文を読むとかける！(素振り) 間違ってたらごめんなさい\n  LinkCutTreeがならしO(logN)らしいし, これもO(logN)だと信じている(解析できねえ\u0026hellip;)\n読んだもの  Maintaining Information in Fully-Dynamic Trees with Top Trees Design and Analysis of Data Structures for Dynamic Trees noshi91さんのツイート  toptree? LinkCutTreeでは, Heavy-edgeのパスを頂点の順番でSplayTreeで管理していました. また, 上のLinkCutTreeでの部分木クエリでは, Light-edgeでつながったものを, multisetで管理しています.\nこれを, Heavy-edgeのパスを辺の順番で, 辺を葉とするSplayTreeで管理し, Light-edgeでつながったものをSplayTreeでまとめたデータ構造が, TopTreeの雑な説明です. このSplayTreeにクエリを処理させれば, 部分木クエリなどができます. link, cutもできます.\nここでもっと雑な説明をしてしまうとTopTreeが分からなくなってしまいそうなので, 他の記事にゆっくりまとめたいと思います\u0026hellip; まとめる時間をください\u0026hellip;(学業がなくなれば)\n実際にできたクエリ TopTreeにはClusterを載せてクエリを処理させます. ClusterのTraitは以下のようになっています.\npub trait Cluster: Clone { fn identity() -\u0026gt; Self; fn compress(left: Self, right: Self) -\u0026gt; Self; fn rake(left: Self, right: Self) -\u0026gt; Self; fn reverse(\u0026amp;amp;mut self); }  v-uパスの長さ impl Cluster for usize { fn identity() -\u0026gt; Self { 0 } fn compress(left: Self, right: Self) -\u0026gt; Self { left + right } fn rake(a: Self, _: Self) -\u0026gt; Self { a } fn reverse(\u0026amp;amp;mut self) {} }  というふうにClusterを定義すると\npub fn path_length_test() { println!(\u0026quot;path_length\u0026quot;); let v: Vec\u0026amp;lt;_\u0026gt; = (0..13).map(|i| Vertex::new(i)).collect(); let edges = [ (0usize, 1usize, 1usize), (1, 2, 10), (1, 3, 3), (1, 4, 4), (0, 5, 3), (5, 9, 4), (9, 10, 7), (10, 11, 9), (10, 12, 1), (0, 6, 3), (6, 7, 3), (7, 8, 7), ]; let mut es = Vec::new(); for (a, b, w) in edges.iter() { es.push(link(v[*a], v[*b], *w)); } assert!(path_query(v[1], v[0]) == 1); assert!(path_query(v[0], v[4]) == 5); assert!(path_query(v[1], v[9]) == 8); assert!(path_query(v[3], v[11]) == 27); assert!(path_query(v[6], v[12]) == 18); assert!(path_query(v[12], v[6]) == 18); assert!(path_query(v[2], v[4]) == 14); assert!(path_query(v[5], v[6]) == 6); }  木の直径クエリ #[derive(Clone, Debug)] struct Diameter { diam: usize, max_dist_left: usize, max_dist_right: usize, length: usize } impl Diameter { fn new(l: usize) -\u0026gt; Self { Diameter { diam: l, max_dist_left: l, max_dist_right: l, length: l, } } } impl Cluster for Diameter { fn identity() -\u0026gt; Self { Diameter { diam: 0, max_dist_left: 0, max_dist_right: 0, length: 0, } } fn compress(a: Self, b: Self) -\u0026gt; Self { Diameter { diam: *[ a.diam, b.diam, a.max_dist_right + b.max_dist_left].into_iter().max().unwrap(), max_dist_left: std::cmp::max(a.max_dist_left, a.length + b.max_dist_left), max_dist_right: std::cmp::max(b.max_dist_right, b.length + a.max_dist_right), length: a.length + b.length } } fn rake(a: Self, b: Self) -\u0026gt; Self { Diameter { diam: *[ a.diam, b.diam, a.max_dist_right + b.max_dist_right ].into_iter().max().unwrap(), max_dist_left: std::cmp::max(a.max_dist_left, a.length + b.max_dist_right), max_dist_right: std::cmp::max(a.max_dist_right, b.max_dist_right), length: a.length, } } fn reverse(\u0026amp;amp;mut self) { std::mem::swap(\u0026amp;amp;mut self.max_dist_left, \u0026amp;amp;mut self.max_dist_right); } }  というふうにClusterを定義すると\npub fn diameter_cut_test() { println!(\u0026quot;diameter cut\u0026quot;); let v: Vec\u0026amp;lt;_\u0026gt; = (0..13).map(|i| Vertex::new(i)).collect(); let edges = [ (0usize, 1usize, 1usize), (1, 2, 10), (1, 3, 3), (1, 4, 4), (0, 5, 3), (5, 9, 4), (9, 10, 7), (10, 11, 9), (10, 12, 1), (0, 6, 3), (6, 7, 3), (7, 8, 7), ]; let mut es = Vec::new(); for (a, b, w) in edges.iter() { es.push(link(v[*a], v[*b], Diameter::new(*w))); } cut(v[0], v[5]); println!(\u0026quot;0 diameter = {}\u0026quot;, expose(v[0]).fold().diam); // -\u0026gt; 24 println!(\u0026quot;5 diameter = {}\u0026quot;, expose(v[5]).fold().diam); // -\u0026gt; 20 }  AOJの直径のやつ適当にいくつか通しました(提出できない)\n最遠点クエリ #[derive(Clone, Debug)] struct Farthest { ans: usize, max_dist_left: usize, max_dist_right: usize, length: usize } impl Farthest { fn new(l: usize) -\u0026gt; Self { Farthest { ans: l, max_dist_left: l, max_dist_right: l, length: l, } } } impl Cluster for Farthest { fn identity() -\u0026gt; Self { Farthest { ans: 0, max_dist_left: 0, max_dist_right: 0, length: 0, } } fn compress(a: Self, b: Self) -\u0026gt; Self { Farthest { ans: std::cmp::max(a.max_dist_right, b.max_dist_left), max_dist_left: std::cmp::max(a.max_dist_left, a.length + b.max_dist_left), max_dist_right: std::cmp::max(b.max_dist_right, b.length + a.max_dist_right), length: a.length + b.length } } fn rake(a: Self, b: Self) -\u0026gt; Self { Farthest { ans: 0, max_dist_left: std::cmp::max(a.max_dist_left, a.length + b.max_dist_right), max_dist_right: std::cmp::max(a.max_dist_right, b.max_dist_right), length: a.length, } } fn reverse(\u0026amp;amp;mut self) { std::mem::swap(\u0026amp;amp;mut self.max_dist_left, \u0026amp;amp;mut self.max_dist_right); } }  というふうにClusterを定義すると\nJ - 仕事をしよう！ (Working!)\nが解けます. サンプルは通りました(AtCoderさんverifyさせてくださいおねがいします)\npub fn farthest_test() { println!(\u0026quot;farthest\u0026quot;); let mut buf = String::new(); std::io::stdin().read_to_string(\u0026amp;amp;mut buf).unwrap(); let mut iter = buf.split_whitespace(); let q: usize = iter.next().unwrap().parse().unwrap(); let mut v: Vec\u0026amp;lt;_\u0026gt; = (0..1).map(|_| Vertex::new(())).collect(); let edges :Vec\u0026amp;lt;(usize, usize, usize)\u0026gt;= (0..q).map(|_| { ( iter.next().unwrap().parse().unwrap(), iter.next().unwrap().parse().unwrap(), iter.next().unwrap().parse().unwrap(), ) }).collect(); let mut es = Vec::new(); for (t, a, c) in edges.iter() { if *t == 1 { let new_v = Vertex::new(()); v.push(new_v); link(v[*a], new_v, Farthest::new(*c)); es.push((*a, v.len() - 1)); } else if *t == 2 { let p = es[*a - 1].0; let q = es[*a - 1].1; cut(v[p], v[q]); link(v[p], v[q], Farthest::new(*c)); } else if *t == 3 { println!(\u0026quot;farthest from {} = {}\u0026quot;, *a, expose(v[*a]).fold().ans); } } }  Nearest Marked Vertex Queryはまだやってない.\n何が載るのかはさっぱりわかりません, だれか解明して.\n","id":11,"section":"posts","summary":"読者層が限定されすぎていませんか？ Link Cut Treeを書いたことがない人はこちら！ Link-Cut 木 - ei1333の日記 部分木クエリについてはこちら！ Link Cut Tre","tags":[],"title":"top-tree実装体験木","uri":"https://niuez.github.io/2019/06/161729/","year":"2019"},{"content":"はじめまして, niuezといいます. 競プロを少ししています.\n最近勉強したことのメモ書きをしておきます.\nダイクストラ法 ダイクストラ法(Dijkstra)は負の長さの無いグラフで始点からの最短距離を求めるアルゴリズムです.\n具体的には\n 距離が未確定の頂点の中で一番小さいものを選び, 距離を確定させる. 選んだ頂点から距離が未確定の頂点に伸びる辺で, 未確定な距離をより短いものに更新する.  を繰り返します. これを実装すると $O(N)$ですが, よく知られるダイクストラの計算量は $O((E+ V) \\log E)$ です(heapとかを使う).\n#include \u0026lt;set\u0026gt;\u0026lt;/set\u0026gt; #include \u0026lt;queue\u0026gt;\u0026lt;/queue\u0026gt; #include \u0026lt;vector\u0026gt;\u0026lt;/vector\u0026gt; struct edge { int u,v; int dist; }; std::vector\u0026amp;lt;int\u0026gt; dijkstra(const std::vector\u0026amp;lt;std::vector\u0026amp;lt;edge\u0026gt;\u0026gt;\u0026amp;amp; g, int s) { std::vector\u0026amp;lt;int\u0026gt; dist(g.size(), 1e9); using node = std::pair\u0026amp;lt;int,int\u0026gt;; std::priority_queue\u0026amp;lt;node,std::vector\u0026amp;lt;node\u0026gt;, std::greater\u0026amp;lt;node\u0026gt;\u0026gt; Q; dist[s] = 0; Q.push(node(dist[s], s)); while(!Q.empty()) { int v = Q.top().second; int d = Q.top().first; Q.pop(); if(dist[v] \u0026amp;lt; d) continue; for(const auto\u0026amp;amp; e: g[v]) { if(dist[e.u] + e.dist \u0026amp;lt; dist[e.v]) { dist[e.v] = dist[e.u] + e.dist; Q.push(node(dist[e.v], e.v)); } } } return std::move(dist); }  ベルマンフォード法 ベルマンフォード法(Bellman-Ford)は任意の長さのグラフで始点からの最短距離を求めるアルゴリズムです. 負の長さの閉路があるときはもちろん求められませんが, この記事では考えないことにします.\n$O(VE)$ で直感的にもわかりやすいアルゴリズムですね.\n#include \u0026lt;vector\u0026gt;\u0026lt;/vector\u0026gt; struct edge { int u,v; int dist; }; std::vector\u0026amp;lt;int\u0026gt; dijkstra(const std::vector\u0026amp;lt;std::vector\u0026amp;lt;edge\u0026gt;\u0026gt;\u0026amp;amp; g, int s) { std::vector\u0026amp;lt;int\u0026gt; dist(g.size(), 1e9); dist[s] = 0; for(int c = 0;c \u0026amp;lt; g.size();c++) { for(int v = 0;v \u0026amp;lt; g.size();g++) { if(dist[v] == (int)1e9) continue; for(const auto\u0026amp;amp; e: g[v]) { if(dist[e.u] + e.dist \u0026amp;lt; dist[e.v]) { dist[e.v] = dist[e.u] + e.dist; } } } } return std::move(dist); }  負の重みがあるときはベルマンフォード法しか無い? ダイクストラ法のほうが定数倍が早かったりするので, できるだけベルマンフォード法よりはダイクストラ法を使いたいですよね?\n一回だけ最短経路を求めるときはベルマンフォード法を使うしかありません.\n複数回最短経路を求めるときはどうでしょうか?\n実はこの場合, ベルマンフォード法を最初に一回だけしておくことで, 後の複数回はダイクストラ法を使うことが出来ます.\nダイクストラ法を使うとすると, 辺の長さをうまいことして正の長さにする必要があります.\n最短経路とは?? 始点を頂点 $s$ とした最短経路を数式に落とし込むと, こういう定義になります.\n$d_s = 0$ とする. すべての辺 $(i,j)$ において $d_i + dist(i,j) \\ge d_j$ が成り立つときの, $d$ のそれぞれの取れる最大値.\nこれを頭に入れておくと次がわかります.\nポテンシャル ここで天才をします. 先人は天才です.\nある$p_i$という値を用意して, 距離を $dist'(i,j) = dist(i,j) + p_i - p_j$ としたグラフを考えます.\n長さ $dist'$ のグラフで, 頂点 $s$ を始点とした最短距離を計算して, ${d'}_i$ を求めたとしましょう.\n${d\u0026#39;}_i + dist\u0026#39;(i, j) \\ge {d\u0026#39;}_j$ ${d\u0026#39;}_i + dist(i, j) + p_i - p_j \\ge {d\u0026#39;}_j$ ${d\u0026#39;}_i + p_i + dist(i, j) \\ge {d\u0026#39;}_j + p_j$ よく見ると\n $d_i = {d\u0026#39;}_i + p_i$  とすれば, $d_i$は最短距離の定義を満たしているように見えますね.しかし\n$d_s = {d\u0026#39;}_s + p_s = p_s`$  なので $d_s = 0$ を満たしていません.  なので, すべての頂点 $i$ について $ans_i = {d'}_i + p_i - p_s$ を計算すれば, $ans$ は最短経路を示しています.\nこのとき, $p_i$ のことをポテンシャルと呼びます.\nでは, $dist'$を正の長さにしたい気持ちになります.\n$dist(i, j) + p_i - p_j \\ge 0$ $p_i + dist(i, j) \\ge p_j$ これは何かな. 最短距離の定義そのままですね(天才).\nこれを使うと色々なものが効率的に求めることが出来ます.\n負の重みがあるグラフでの全点間最短距離問題 全点間最短距離問題とは, すべての頂点の間での最短距離を計算する問題のことです.\nよく知られているのはワーシャルフロイド法の $O(V3)$ ですが, これを $V$ 回のダイクストラに置き換えることが出来て, $O(V(E + V) \\log V)$ になります.\n疑似コード\nproc all_pair_shortest_path(G, dist) let potential = bellman_ford(G, dist, 0) //引数は グラフ, 距離, 始点 です for e = (i, j) in G dist2(i, j) = dist(i, j) + potential[i] - potential[j] for s in [0, |V| - 1] result[s] = dijkstra(G, dist2, s) for j in [0, |V| - 1] result[s][j] += potential[j] - potential[s] // result[s][j]... s -\u0026gt; jの距離 return result  最小費用流 最小費用流はたぶん皆さんなら, 最短路反復法で実装していると思いますが\u0026hellip;(RHS-algorithmなんて強多項式計算量知らない)\nこのとき負の辺があるときはダイクストラが使えないと思われがちですが, 同じように最初にベルマンフォードでポテンシャルを求めておけば, 高速で計算が可能です.\nしかし, 逆辺が負の重みを持つので, ポテンシャルは, その時求めた最短距離を加算して行くことで, 更新をし続けなければなりません.\nlibalgoが参考になります.\nスケーリングアルゴリズム スケーリングを用いたダイクストラのアルゴリズムは重みが非負整数のときに使える高速化手法です.\n簡潔に言うと, 「辺の重みを半分にしたものでダイクストラをして, その結果の二倍をポテンシャルに使ってダイクストラをする.」 を再帰的に行うことで, ダイクストラを高速化するテクを使うというアルゴリズムです.\n下に例を示します.\n  このようなグラフがあったとします.\nこのグラフの重みを半分にした(小数点以下切り捨て) グラフでダイクストラをします.\n  最短距離は赤色に示した通りです.\nこの値を二倍した値を, 半分にする前のグラフのポテンシャルに使います.\n  辺の重みをポテンシャルによって置き換えると以下のようになります.\n  この置き換えた重みでダイクストラをします.\n  最短距離は青色で示しました.\nそれぞれの頂点で赤色と青色の値を足すと, ポテンシャルの性質により半分にする前のグラフの最短距離が求まります.\n  このグラフの重みは二進数にしたとき高々2桁なので1回半分にするだけで済みましたが, 一般に $ \\log W$ 回再帰的に「重みを半分にして二倍してポテンシャルに使う」という動作をすれば求まります.\n高速化 正直こんなことしなくてもこのままのアルゴリズムであれば, 大元のグラフをダイクストラすればいいだけの話です.\nですが, このポテンシャルで変更を加えた後のグラフに性質があります.\n重みを半分にしたグラフでの, 頂点$s$から頂点$g$の最短経路($P$とします)に含まれる辺の数を $L$とします.\nこのとき, 半分にする前の重みをポテンシャルで変更を加えたグラフでの $s$から$g$の最短経路の重みは $L$以下です.\nなぜなら, 二進数を考えると$P$上の辺の重みはポテンシャルで変更を加えると $0$ か $1$にしかならないからです.\nつまりこのスケーリングアルゴリズムで行うダイクストラは, $V$個のQueueを用意してダイクストラをするものを使えば $O(m + n \\log W)$ で計算できます.\n〆 実はダイクストラの定数倍が速すぎてスケーリングはそんなに速くなりません\n","id":12,"section":"posts","summary":"はじめまして, niuezといいます. 競プロを少ししています. 最近勉強したことのメモ書きをしておきます. ダイクストラ法 ダイクストラ法(Dijk","tags":[],"title":"ダイクストラとポテンシャルのはなし","uri":"https://niuez.github.io/2019/03/142903/","year":"2019"}],"tags":[{"title":"DFS","uri":"https://niuez.github.io/tags/dfs/"},{"title":"Divisor","uri":"https://niuez.github.io/tags/divisor/"},{"title":"GCD","uri":"https://niuez.github.io/tags/gcd/"},{"title":"LCA","uri":"https://niuez.github.io/tags/lca/"},{"title":"LCM","uri":"https://niuez.github.io/tags/lcm/"},{"title":"Mobius","uri":"https://niuez.github.io/tags/mobius/"},{"title":"Transform","uri":"https://niuez.github.io/tags/transform/"},{"title":"Tree","uri":"https://niuez.github.io/tags/tree/"}]}