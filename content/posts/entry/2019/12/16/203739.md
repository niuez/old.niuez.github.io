
+++
date = "2019-12-16 20:37:39 +0000 UTC"
draft = false
title = "Suffix Array と LCP と 文字列検索の実装をした"
tags = ["Algorithm"]

+++
この土日のメモです. SAとLCPのお気持ちをまとめたくなっただけ. 間違ってたらごめん

>文字列アルゴの勉強する気が起きないたった一つの理由: Rolling Hash— νιυεζ (@xiuez) 2019年12月13日<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

これをやめたいので, 手始めにSuffix Arrayを使った文字列検索をやってみようかなというのが今回の主題

## 概要

<ul>
<li>SA-ISでSuffix Arrayを構築$ O(|S|)$</li>
<li>LCP配列の構築$ O(|S|)$</li>
<li>LCPによるSuffix同士のLCPをSparse Tableで構築$ O(|S| \log{|S|})$, クエリ$ O(1)$</li>
<li>Suffix Arrayの二分探索で文字列検索を$ O(|T| log{|S|})$</li>
<li>Suffix ArrayとLCPの二分探索で文字列検索を構築$ O(|S|)$, クエリ$ O(|T| + \log{|S|})$</li>
</ul>


の実装をやってみました. このときのメモを残しておきたいと思います.

各用語の説明はここではしません... 他の記事や, <a href="https://www.amazon.co.jp/%E3%83%97%E3%83%AD%E3%82%B0%E3%83%A9%E3%83%9F%E3%83%B3%E3%82%B0%E3%82%B3%E3%83%B3%E3%83%86%E3%82%B9%E3%83%88%E3%83%81%E3%83%A3%E3%83%AC%E3%83%B3%E3%82%B8%E3%83%96%E3%83%83%E3%82%AF-%E7%AC%AC2%E7%89%88-%EF%BD%9E%E5%95%8F%E9%A1%8C%E8%A7%A3%E6%B1%BA%E3%81%AE%E3%82%A2%E3%83%AB%E3%82%B4%E3%83%AA%E3%82%BA%E3%83%A0%E6%B4%BB%E7%94%A8%E5%8A%9B%E3%81%A8%E3%82%B3%E3%83%BC%E3%83%87%E3%82%A3%E3%83%B3%E3%82%B0%E3%83%86%E3%82%AF%E3%83%8B%E3%83%83%E3%82%AF%E3%82%92%E9%8D%9B%E3%81%88%E3%82%8B%EF%BD%9E-%E7%A7%8B%E8%91%89%E6%8B%93%E5%93%89/dp/4839941068">蟻本 - Amazon</a>を参考に.

## SA-IS

Suffix Arrayの実装は蟻本にも載っていますが, そこまで早くありません... SA-ISというアルゴリズムが早いらしいのでこれを実装します.

SA-ISの理解には, この記事がとても参考になりました. とてもわかりやすい記事です.

[ SA-IS 法のメモ - まめめも](https://mametter.hatenablog.com/entry/20180130/p1)

SA-ISの実装は<a href="https://judge.yosupo.jp/submission/1069">yosupoさんのコード</a>を見ました.

僕が書いたSA-ISのコードはこれです.

[Submitted](https://judge.yosupo.jp/submission/1908)

<ul>
<li>メモリを使い回す(resizeの回数を減らしてメモリを使いまわしても, assignが割と早くてこれが非自明)</li>
<li><code>push_back</code>をなくす</li>
<li>入出力の早いライブラリを使うともっと早くなります</li>
</ul>


実はSA-ISの論文に実装が載っていてそれがとても速いです. ぜひ参考にしてみてください.

以下, 文字列<code>S</code>のSuffix Arrayを<code>SA</code>とします. <code>S</code>の辞書順で<code>i</code>番目に小さいsuffixを<code>Suf[i] := S[SA[i]...]</code>とします.

## LCP(Longest Common Prefix)

LCP配列は, Suffix Arrayで隣り合ったSuffix(つまり, <code>Suf[i]とSuf[i + 1]</code>)の最長共通接頭辞を求めた配列です. Kasai&#39;s Algorithmを用いて$ O(|S|)$で構築できます.

LCPの理解は以下の記事がわかりやすいです. 蟻本にもあるはず.

[LCP配列 (Kasai’s algorithm)](https://lumakernel.github.io/ecasdqina/string/LCP-Array)

例は,
<a href="https://ei1333.github.io/luzhiled/snippets/string/suffix-array.html">接尾辞配列(Suffix-Array) | Luzhiled’s memo</a> がわかりやすいです.

僕の実装は先頭に無(空配列)があるので, 以下のようになります.

```
i :lcp
0 : 0 
1 : 0 a
2 : 1 abra
3 : 4 abracadabra
4 : 1 acadabra
5 : 1 adabra
6 : 0 bra
7 : 3 bracadabra
8 : 0 cadabra
9 : 0 dabra
10: 0 ra
11: 2 racadabra
```


## 任意のsuffix同士のLCP

上の例で, <code>i = 2, abra</code>と, <code>j = 5, adabra</code>のLCPを求めるとすると, <code>3, 4, 5</code>の<code>lcp</code>の最小値である<code>1</code>がその答えになります.

Suffix Arrayで, indexが $ i$ のsuffixと $ j$ のsuffixのLCPは, $ [i + 1, j + 1)$ 間の<code>lcp</code>の最小値になります.

なので, <code>lcp</code>をSparse Tableに載せると構築 $ O(|S| \log{|S|})$, クエリ$ O(1)$で処理できます.

## Suffix Arrayで文字列検索

文字列<code>S</code>のSuffix Array <code>SA</code>を使って, <code>S</code>の中に文字列<code>T</code>があるかどうかを二分探索で処理できます. これは, Suffix Arrayによって各suffixがソートされているのを利用しています.

計算量は$ O(|T| \log{|S|})$です. <a href="https://onlinejudge.u-aizu.ac.jp/status/users/niuez/submissions/1/ALDS1_14_D/judge/4048844/C++14">AOJの提出コード</a>

```cpp
cin >> t;
int L = 0;
int R = sa.size();
while(R - L > 1) {
  int M = (L + R) >> 1;
  if(s.substr(sa[M], t.size()) &lt;= t) {
    L = M;
  }
  else {
    R = M;
  }
}
cout &lt;&lt; (s.substr(sa[L], t.size()) == t) &lt;&lt; endl;

```


これがかなりはやい なんでだろう

## SAとLCPで文字列検索

この二分探索はさらに高速化できます. suffixとTの比較を最小限にすることで, $ O(|T| + \log{|S|})$を達成します.

具体的には, <code>suf[L]</code>とTのLCPを常に持ちながら二分探索をします. このLCPを<code>Llcp</code>とします.  <code>M = (L + R) / 2</code>として, <code>suf[L]</code>と<code>suf[M]</code>のLCPを求めて, <code>nlcp</code>とします. <code>nlcp</code>は先に書いたとおり, Sparse Tableで求めることができます.  次に<code>Llcp</code>と<code>nlcp</code>を比較します.

<ul>
<li><strong><code>Llcp &lt; nlcp</code></strong>のとき</li>
</ul>


以下の例で考えてみます. (Suffix Arrayではありませんが, 複数の文字列を辞書順にソートしたという意味で同じです)

```
T = ad

L : aaa
    aaab
    aaac
M : aac
    aacc
    ba
R : 

Llcp = LCP(aaa, ad) = 1  // "a"aa, "a"dなので
nlcp = LCP(aaa, aac) = 2 // "aa"a, "aa"cなので
```


<code>T</code>は辞書順で<code>suf[T]</code>以上ということがわかっているので, <code>Llcp &lt; nlcp</code>より, Tと<code>suf[M]</code>のLCPは<code>Llcp</code>であり, <code>T</code>は辞書順で<code>suf[M]</code>以上です.  なので, Llcpはそのままで, <code>L = M</code>とします.

<ul>
<li><strong><code>Llcp > nlcp</code></strong>のとき</li>
</ul>


```
T = aaac

L : aaa
    aaab
    aaac
M : aac
    aacc
    ba
R : 

Llcp = LCP(aaa, aaac) = 3  // "aaa", "aaa"cなので
nlcp = LCP(aaa, aac) = 2 // "aa"a, "aa"cなので
```


T<code>と</code>suf[M]<code>のLCPは</code>nlcp<code>であり,</code>T<code>は辞書順で</code>suf[M]<code>未満です. なので, Llcpはそのままで,</code>R = M`とします.

<ul>
<li><strong><code>Llcp = nlcp</code></strong>のとき</li>
</ul>


```
T = aacc

L : aaa
    aaab
    aaac
M : aac
    aacc
    ba
R : 

Llcp = LCP(aaa, aacc) = 2  // "aa"a, "aa"ccなので
nlcp = LCP(aaa, aac) = 2 // "aa"a, "aa"cなので
```


このときは, <code>T</code>と<code>suf[M]</code>の辞書順の関係がわからないので比較をします. このとき, <strong>LCPの部分は一致していることがわかっているので比較をしなくてよい</strong>です. 比較をした後, Llcpを比較をした時の計算結果を利用して更新します.

<code>Llcp</code>は探索中, 単調増加します. なので, 文字列の比較が全体で$ O(|T|)$しかされません. これにより, 計算量が改善されます.

実際にコードを示します.

```cpp
std::pair&lt;int, int> get_lcp(const std::vector&lt;T>&amp; t, int si, int offset) {
  int i = offset;
  si += offset;
  while(i &lt; t.size() &amp;&amp; si &lt; N) {
    if(t[i] != str[si]) {
      return { i, t[i] - str[si] };
    }
    i++;
    si++;
  }
  return { i, 0 };
}

std::pair&lt;int, int> search(const std::vector&lt;T>&amp; t) {
  int L = 0;
  int R = N + 1;
  int Llcp = 0;

  while(R - L > 1) {
    int M = (L + R) >> 1;
    int nlcp = st.query(L + 1, M + 1);
    if(Llcp &lt; nlcp) {
      L = M;
    }
    else if(Llcp > nlcp) {
      R = M;
    }
    else {
      auto p = get_lcp(t, sa[M], Llcp);
      if(p.second >= 0) {
        L = M;
        Llcp = p.first;
      }
      else if(p.second &lt; 0) {
        R = M;
      }
    }
  }

  return { Llcp, L };
}

```


これで早くなるはず...!

[Aizu Online Judge](https://onlinejudge.u-aizu.ac.jp/status/users/niuez/submissions/2/ALDS1_14_D/judge/4048629/C++14)

5倍遅くなった...

## Sparse Tableの構築が重すぎる

$ O(|S| \log{|S|})$ 流石に重い... 改善したい

## Sparse Tableを使わない方法で改善

二分探索だけならSparse Tableである必要はありません. Segment Treeを使います.<br/>
二分探索で最小値を求めたい区間は必ず<code>[L, (L + R) / 2)</code>に対応できます. なので, 二分探索するときに, Segment Treeのノードを降りていくようにすると 構築$ O(|S|)$で二分探索ができるようになります.

コードはこんな感じ

```cpp
...
...
  seg_n = 1;
  while(seg_n &lt; N + 1) seg_n &lt;&lt;= 1;
  seg.resize(seg_n * 2, 1e9);
  for(int i = 0;i + 1 &lt; N + 1;i++) {
    seg[i + seg_n - 1] = lcp[i + 1];
  }
  for(int i = seg_n - 1; i --> 0;) {
    seg[i] = std::min(seg[(i &lt;&lt; 1) + 1], seg[(i &lt;&lt; 1) + 2]);
  }
}

std::pair&lt;int, int> get_lcp(const std::vector&lt;T>&amp; t, int sa_i, int offset) {
  if(sa_i > N) return { offset, -1 };
  int i = offset;
  int si = sa[sa_i] + offset;
  while(i &lt; t.size() &amp;&amp; si &lt; N) {
    if(t[i] != str[si]) {
      return { i, t[i] - str[si] };
    }
    i++;
    si++;
  }
  return { i, 1 };
}

std::pair&lt;int, int> search(const std::vector&lt;T>&amp; t) {
  int L = 0;
  int R = seg_n;
  int Llcp = 0;
  int j = 0;

  while(R - L > 1) {
    int M = (L + R) >> 1;
    int nlcp = seg[(j &lt;&lt; 1) + 1];
    if(nlcp == 1e9) {
      j = (j &lt;&lt; 1) + 1;
      R = M;
    }
    else if(Llcp &lt; nlcp) {
      j = (j &lt;&lt; 1) + 2;
      L = M;
    }
    else if(Llcp > nlcp) {
      j = (j &lt;&lt; 1) + 1;
      R = M;
    }
    else {
      auto p = get_lcp(t, M, Llcp);
      if(p.second >= 0) {
        j = (j &lt;&lt; 1) + 2;
        L = M;
        Llcp = p.first;
      }
      else if(p.second &lt; 0) {
        j = (j &lt;&lt; 1) + 1;
        R = M;
      }
    }
  }

  return { Llcp, L };
}

```


[Aizu Online Judge](https://onlinejudge.u-aizu.ac.jp/status/users/niuez/submissions/1/ALDS1_14_D/judge/4050033/C++14)

これでも最初の二分探索に勝てませんでした... なんでだろう でもこれでもかなり速いです.

## しめ

FM-indexとかやってみたくなりました


